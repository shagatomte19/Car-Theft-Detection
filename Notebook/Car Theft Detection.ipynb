{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["CpgHDaIz_ETV","oXDW4lfJ_759"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Libraries and other things**"],"metadata":{"id":"RhiLTL8h-0Sx"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sXDyomn_3no","executionInfo":{"status":"ok","timestamp":1743031820548,"user_tz":-360,"elapsed":45466,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"16fa18b7-5f17-49c9-ada3-b3daeaf2235d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"9Poogfm5rMz4","executionInfo":{"status":"error","timestamp":1743038959559,"user_tz":-360,"elapsed":116,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"78a9ebd0-03b5-4520-8f40-b7d4639922e4"},"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"A UTF-8 locale is required. Got ANSI_X3.4-1968","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-1f59a196e0d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install ultralytics opencv-python torch torchvision torchaudio kaleido'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n","\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"]}],"source":["!pip install ultralytics opencv-python torch torchvision torchaudio"]},{"cell_type":"code","source":["import os\n","import cv2\n","import glob\n","import shutil\n","import torch\n","import zipfile\n","from ultralytics import YOLO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gE3Wx61IrviP","executionInfo":{"status":"ok","timestamp":1743031938049,"user_tz":-360,"elapsed":13379,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"e019bba9-9b53-470f-f26f-7441e2a335ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"markdown","source":["# **Dataset Loading**"],"metadata":{"id":"BTNKQsN2_ACO"}},{"cell_type":"code","source":["dataset_path = \"/content/drive/MyDrive/Car Theft Model/Dataset\""],"metadata":{"id":"xVVFVsCCwTKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_img_dir = os.path.join(dataset_path, \"train\", \"images\")\n","train_lbl_dir = os.path.join(dataset_path, \"train\", \"labels\")\n","val_img_dir = os.path.join(dataset_path, \"valid\", \"images\")\n","val_lbl_dir = os.path.join(dataset_path, \"valid\", \"labels\")\n","test_img_dir = os.path.join(dataset_path, \"test\", \"images\")\n","test_lbl_dir = os.path.join(dataset_path, \"test\", \"labels\")\n","yaml_path = os.path.join(dataset_path, \"data.yaml\")\n","print(train_img_dir)\n","print(train_lbl_dir)\n","print(val_img_dir)\n","print(val_lbl_dir)\n","print(test_img_dir)\n","print(test_lbl_dir)\n","print(yaml_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kQ3fthADwVsW","executionInfo":{"status":"ok","timestamp":1743037284182,"user_tz":-360,"elapsed":6,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"825ea3be-0e97-4d30-e78d-4d9a29263998"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Car Theft Model/Dataset/train/images\n","/content/drive/MyDrive/Car Theft Model/Dataset/train/labels\n","/content/drive/MyDrive/Car Theft Model/Dataset/valid/images\n","/content/drive/MyDrive/Car Theft Model/Dataset/valid/labels\n","/content/drive/MyDrive/Car Theft Model/Dataset/test/images\n","/content/drive/MyDrive/Car Theft Model/Dataset/test/labels\n","/content/drive/MyDrive/Car Theft Model/Dataset/data.yaml\n"]}]},{"cell_type":"markdown","source":["# **Preprocessing**"],"metadata":{"id":"CpgHDaIz_ETV"}},{"cell_type":"code","source":["base_dir = \"/content/drive/MyDrive/Car Theft Model/Dataset\"\n","\n","\n","for folder in [\"train\", \"test\", \"valid\"]:\n","    labels_path = os.path.join(base_dir, folder, \"labels\")\n","\n","    if not os.path.exists(labels_path):\n","        print(f\"üö® Path does not exist: {labels_path}\")\n","        continue\n","\n","    # Rename files\n","    for filename in os.listdir(labels_path):\n","        file_path = os.path.join(labels_path, filename)\n","\n","\n","        if not filename.endswith(\".txt\"):\n","            new_filename = filename + \".txt\"\n","            new_file_path = os.path.join(labels_path, new_filename)\n","\n","            try:\n","                os.rename(file_path, new_file_path)\n","                print(f\"‚úÖ Renamed: {filename} ‚Üí {new_filename}\")\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Error renaming {filename}: {e}\")\n","\n","print(\"üéâ Renaming complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wxlp7rx1ywmI","executionInfo":{"status":"ok","timestamp":1742666821697,"user_tz":-360,"elapsed":3305,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"6f3c9551-8345-46f5-c8f6-1f1f6caaf888"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéâ Renaming complete!\n"]}]},{"cell_type":"code","source":["# 640 x 640\n","def resize_images(image_folder, target_size=(640, 640)):\n","    image_files = glob.glob(f\"{image_folder}/*.jpg\")\n","    total_images = len(image_files)\n","    for idx, img_file in enumerate(image_files):\n","        img = cv2.imread(img_file)\n","        img = cv2.resize(img, target_size)\n","        cv2.imwrite(img_file, img)\n","        print(f\"Processed {idx+1}/{total_images} images in {image_folder}\")\n","\n","resize_images(train_img_dir)\n","resize_images(val_img_dir)\n","resize_images(test_img_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nfdBBnww0tS","executionInfo":{"status":"ok","timestamp":1742645609680,"user_tz":-360,"elapsed":87418,"user":{"displayName":"Enamul Hasan Shagato","userId":"14285575252338270535"}},"outputId":"32c17258-12cd-432b-a5f6-e71339865ae9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 1/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 2/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 3/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 4/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 5/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 6/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 7/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 8/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 9/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 10/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 11/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 12/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 13/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 14/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 15/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 16/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 17/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 18/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 19/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 20/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 21/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 22/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 23/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 24/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 25/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 26/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 27/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 28/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 29/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 30/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 31/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 32/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 33/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 34/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 35/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 36/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 37/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 38/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 39/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 40/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 41/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 42/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 43/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 44/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 45/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 46/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 47/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 48/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 49/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 50/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 51/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 52/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 53/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 54/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 55/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 56/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 57/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 58/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 59/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 60/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 61/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 62/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 63/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 64/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 65/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 66/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 67/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 68/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 69/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 70/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 71/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 72/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 73/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 74/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 75/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 76/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 77/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 78/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 79/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 80/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 81/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 82/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 83/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 84/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 85/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 86/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 87/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 88/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 89/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 90/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 91/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 92/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 93/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 94/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 95/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 96/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 97/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 98/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 99/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 100/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 101/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 102/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 103/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 104/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 105/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 106/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 107/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 108/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 109/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 110/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 111/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 112/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 113/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 114/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 115/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 116/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 117/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 118/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 119/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 120/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 121/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 122/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 123/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 124/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 125/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 126/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 127/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 128/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 129/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 130/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 131/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 132/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 133/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 134/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 135/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 136/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 137/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 138/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 139/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 140/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 141/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 142/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 143/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 144/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 145/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 146/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 147/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 148/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 149/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 150/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 151/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 152/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 153/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 154/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 155/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 156/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 157/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 158/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 159/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 160/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 161/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 162/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 163/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 164/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 165/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 166/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 167/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 168/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 169/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 170/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 171/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 172/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 173/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 174/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 175/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 176/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 177/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 178/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 179/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 180/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 181/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 182/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 183/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 184/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 185/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 186/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 187/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 188/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 189/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 190/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 191/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 192/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 193/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 194/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 195/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 196/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 197/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 198/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 199/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 200/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 201/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 202/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 203/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 204/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 205/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 206/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 207/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 208/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 209/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 210/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 211/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 212/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 213/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 214/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 215/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 216/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 217/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 218/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 219/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 220/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 221/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 222/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 223/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 224/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 225/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 226/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 227/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 228/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 229/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 230/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 231/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 232/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 233/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 234/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 235/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 236/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 237/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 238/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 239/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 240/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 241/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 242/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 243/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 244/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 245/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 246/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 247/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 248/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 249/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 250/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 251/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 252/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 253/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 254/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 255/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 256/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 257/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 258/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 259/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 260/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 261/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 262/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 263/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 264/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 265/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 266/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 267/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 268/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 269/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 270/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 271/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 272/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 273/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 274/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 275/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 276/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 277/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 278/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 279/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 280/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 281/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 282/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 283/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 284/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 285/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 286/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 287/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 288/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 289/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 290/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 291/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 292/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 293/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 294/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 295/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 296/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 297/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 298/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 299/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 300/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 301/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 302/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 303/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 304/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 305/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 306/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 307/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 308/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 309/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 310/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 311/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 312/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 313/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 314/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 315/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 316/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 317/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 318/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 319/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 320/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 321/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 322/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 323/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 324/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 325/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 326/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 327/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 328/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 329/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 330/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 331/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 332/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 333/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 334/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 335/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 336/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 337/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 338/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 339/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 340/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 341/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 342/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 343/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 344/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 345/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 346/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 347/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 348/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 349/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 350/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 351/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 352/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 353/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 354/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 355/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 356/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 357/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 358/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 359/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 360/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 361/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 362/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 363/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 364/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 365/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 366/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 367/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 368/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 369/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 370/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 371/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 372/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 373/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 374/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 375/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 376/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 377/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 378/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 379/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 380/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 381/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 382/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 383/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 384/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 385/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 386/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 387/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 388/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 389/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 390/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 391/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 392/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 393/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 394/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 395/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 396/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 397/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 398/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 399/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 400/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 401/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 402/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 403/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 404/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 405/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 406/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 407/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 408/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 409/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 410/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 411/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 412/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 413/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 414/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 415/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 416/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 417/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 418/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 419/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 420/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 421/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 422/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 423/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 424/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 425/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 426/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 427/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 428/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 429/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 430/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 431/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 432/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 433/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 434/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 435/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 436/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 437/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 438/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 439/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 440/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 441/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 442/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 443/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 444/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 445/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 446/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 447/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 448/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 449/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 450/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 451/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 452/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 453/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 454/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 455/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 456/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 457/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 458/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 459/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 460/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 461/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 462/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 463/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 464/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 465/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 466/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 467/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 468/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 469/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 470/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 471/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 472/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 473/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 474/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 475/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 476/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 477/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 478/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 479/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 480/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 481/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 482/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 483/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 484/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 485/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 486/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 487/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 488/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 489/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 490/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 491/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 492/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 493/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 494/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 495/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 496/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 497/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 498/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 499/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 500/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 501/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 502/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 503/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 504/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 505/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 506/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 507/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 508/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 509/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 510/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 511/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 512/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 513/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 514/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 515/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 516/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 517/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 518/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 519/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 520/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 521/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 522/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 523/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 524/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 525/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 526/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 527/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 528/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 529/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 530/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 531/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 532/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 533/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 534/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 535/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 536/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 537/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 538/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 539/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 540/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 541/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 542/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 543/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 544/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 545/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 546/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 547/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 548/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 549/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 550/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 551/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 552/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 553/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 554/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 555/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 556/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 557/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 558/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 559/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 560/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 561/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 562/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 563/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 564/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 565/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 566/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 567/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 568/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 569/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 570/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 571/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 572/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 573/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 574/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 575/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 576/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 577/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 578/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 579/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 580/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 581/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 582/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 583/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 584/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 585/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 586/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 587/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 588/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 589/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 590/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 591/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 592/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 593/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 594/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 595/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 596/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 597/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 598/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 599/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 600/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 601/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 602/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 603/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 604/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 605/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 606/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 607/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 608/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 609/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 610/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 611/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 612/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 613/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 614/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 615/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 616/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 617/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 618/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 619/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 620/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 621/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 622/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 623/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 624/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 625/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 626/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 627/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 628/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 629/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 630/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 631/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 632/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 633/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 634/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 635/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 636/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 637/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 638/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 639/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 640/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 641/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 642/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 643/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 644/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 645/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 646/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 647/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 648/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 649/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 650/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 651/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 652/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 653/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 654/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 655/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 656/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 657/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 658/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 659/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 660/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 661/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 662/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 663/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 664/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 665/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 666/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 667/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 668/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 669/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 670/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 671/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 672/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 673/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 674/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 675/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 676/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 677/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 678/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 679/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 680/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 681/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 682/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 683/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 684/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 685/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 686/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 687/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 688/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 689/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 690/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 691/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 692/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 693/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 694/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 695/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 696/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 697/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 698/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 699/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 700/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 701/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 702/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 703/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 704/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 705/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 706/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 707/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 708/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 709/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 710/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 711/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 712/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 713/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 714/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 715/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 716/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 717/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 718/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 719/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 720/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 721/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 722/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 723/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 724/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 725/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 726/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 727/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 728/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 729/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 730/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 731/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 732/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 733/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 734/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 735/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 736/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 737/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 738/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 739/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 740/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 741/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 742/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 743/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 744/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 745/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 746/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 747/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 748/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 749/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 750/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 751/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 752/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 753/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 754/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 755/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 756/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 757/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 758/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 759/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 760/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 761/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 762/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 763/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 764/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 765/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 766/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 767/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 768/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 769/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 770/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 771/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 772/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 773/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 774/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 775/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 776/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 777/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 778/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 779/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 780/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 781/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 782/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 783/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 784/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 785/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 786/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 787/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 788/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 789/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 790/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 791/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 792/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 793/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 794/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 795/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 796/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 797/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 798/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 799/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 800/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 801/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 802/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 803/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 804/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 805/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 806/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 807/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 808/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 809/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 810/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 811/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 812/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 813/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 814/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 815/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 816/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 817/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 818/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 819/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 820/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 821/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 822/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 823/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 824/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 825/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 826/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 827/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 828/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 829/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 830/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 831/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 832/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 833/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 834/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 835/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 836/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 837/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 838/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 839/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 840/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 841/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 842/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 843/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 844/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 845/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 846/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 847/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 848/848 images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images\n","Processed 1/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 2/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 3/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 4/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 5/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 6/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 7/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 8/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 9/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 10/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 11/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 12/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 13/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 14/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 15/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 16/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 17/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 18/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 19/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 20/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 21/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 22/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 23/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 24/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 25/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 26/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 27/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 28/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 29/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 30/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 31/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 32/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 33/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 34/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 35/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 36/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 37/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 38/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 39/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 40/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 41/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 42/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 43/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 44/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 45/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 46/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 47/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 48/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 49/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 50/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 51/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 52/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 53/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 54/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 55/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 56/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 57/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 58/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 59/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 60/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 61/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 62/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 63/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 64/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 65/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 66/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 67/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 68/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 69/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 70/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 71/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 72/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 73/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 74/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 75/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 76/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 77/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 78/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 79/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 80/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 81/81 images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images\n","Processed 1/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 2/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 3/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 4/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 5/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 6/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 7/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 8/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 9/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 10/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 11/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 12/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 13/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 14/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 15/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 16/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 17/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 18/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 19/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 20/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 21/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 22/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 23/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 24/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 25/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 26/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 27/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 28/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 29/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 30/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 31/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 32/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 33/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 34/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 35/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 36/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 37/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 38/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 39/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n","Processed 40/40 images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images\n"]}]},{"cell_type":"code","source":["def match_files(img_dir, lbl_dir):\n","  img_files = set([os.path.splitext(os.path.basename(f))[0] for f in glob.glob(os.path.join(img_dir, \"*.jpg\"))])\n","  lbl_files = set([os.path.splitext(os.path.basename(f))[0] for f in glob.glob(os.path.join(lbl_dir, \"*.txt\"))])\n","\n","  unmatched_images = img_files - lbl_files\n","  unmatched_labels = lbl_files - img_files\n","\n","  print(f\"Unmatched images in {img_dir}: {len(unmatched_images)}\")\n","  print(f\"Unmatched labels in {lbl_dir}: {len(unmatched_labels)}\")\n","\n","  return unmatched_images, unmatched_labels\n","\n","\n","\n","train_unmatched_images, train_unmatched_labels = match_files(train_img_dir, train_lbl_dir)\n","val_unmatched_images, val_unmatched_labels = match_files(val_img_dir, val_lbl_dir)\n","test_unmatched_images, test_unmatched_labels = match_files(test_img_dir, test_lbl_dir)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSJ8b-ET6u9G","executionInfo":{"status":"ok","timestamp":1743026346244,"user_tz":-360,"elapsed":12,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"699c7fe3-fdd7-454a-fbab-03e364b5921a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unmatched images in /content/drive/MyDrive/Colab Notebooks/Dataset/train/images: 0\n","Unmatched labels in /content/drive/MyDrive/Colab Notebooks/Dataset/train/labels: 0\n","Unmatched images in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/images: 0\n","Unmatched labels in /content/drive/MyDrive/Colab Notebooks/Dataset/valid/labels: 0\n","Unmatched images in /content/drive/MyDrive/Colab Notebooks/Dataset/test/images: 0\n","Unmatched labels in /content/drive/MyDrive/Colab Notebooks/Dataset/test/labels: 0\n"]}]},{"cell_type":"code","source":["def calculate_mismatch_percentage(img_dir, lbl_dir):\n","  img_files = set([os.path.splitext(os.path.basename(f))[0] for f in glob.glob(os.path.join(img_dir, \"*.jpg\"))])\n","  lbl_files = set([os.path.splitext(os.path.basename(f))[0] for f in glob.glob(os.path.join(lbl_dir, \"*.txt\"))])\n","\n","  total_files = len(img_files)\n","  if total_files == 0:\n","    return 0.0\n","\n","  unmatched_count = len(img_files - lbl_files) + len(lbl_files - img_files)\n","  mismatch_percentage = (unmatched_count / total_files) * 100\n","\n","  return mismatch_percentage\n","\n","\n","train_mismatch_percentage = calculate_mismatch_percentage(train_img_dir, train_lbl_dir)\n","val_mismatch_percentage = calculate_mismatch_percentage(val_img_dir, val_lbl_dir)\n","test_mismatch_percentage = calculate_mismatch_percentage(test_img_dir, test_lbl_dir)\n","\n","\n","print(f\"Train set mismatch percentage: {train_mismatch_percentage:.2f}%\")\n","print(f\"Validation set mismatch percentage: {val_mismatch_percentage:.2f}%\")\n","print(f\"Test set mismatch percentage: {test_mismatch_percentage:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9Ae5fX-H8ac","executionInfo":{"status":"ok","timestamp":1742666871438,"user_tz":-360,"elapsed":53,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"f726d136-09a6-49e4-dc09-0563ae6281f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set mismatch percentage: 0.00%\n","Validation set mismatch percentage: 0.00%\n","Test set mismatch percentage: 0.00%\n"]}]},{"cell_type":"code","source":["labels_folder = \"/content/drive/MyDrive/Car Theft Model/Dataset/valid/labels\"\n","\n","def clean_bom_from_labels(folder_path):\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, filename)\n","\n","            with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n","                lines = f.readlines()\n","\n","            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n","                f.writelines(lines)\n","\n","            print(f\"‚úÖ Cleaned BOM from: {filename}\")\n","\n","clean_bom_from_labels(labels_folder)\n","print(\"üöÄ All label files are cleaned and ready!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGM5_se-DVb9","executionInfo":{"status":"ok","timestamp":1742667169907,"user_tz":-360,"elapsed":872,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"970859b1-25d5-4ebf-8d0a-ac9935354941"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Cleaned BOM from: fdbb92e8-dcac-11ef-9634-0242ac1c000c_jpg.rf.7d9d6b812e157dc4d6ca96eead2f6777.txt\n","‚úÖ Cleaned BOM from: ecc52cc4-dcac-11ef-9634-0242ac1c000c_jpg.rf.d0dc17c9ea95960aa63fb564881eb0a2.txt\n","‚úÖ Cleaned BOM from: fde6b16c-dcac-11ef-9634-0242ac1c000c_jpg.rf.12c1306c11f7c52cbda3a561532089cc.txt\n","‚úÖ Cleaned BOM from: e5a65b52-dcac-11ef-9634-0242ac1c000c_jpg.rf.33339e26b3321c94ade0fd4e7229b307.txt\n","‚úÖ Cleaned BOM from: e5ae7b70-dcac-11ef-9634-0242ac1c000c_jpg.rf.a291c4011e2f3e7a297efd7884ce0074.txt\n","‚úÖ Cleaned BOM from: dd29f3fc-dcad-11ef-9634-0242ac1c000c_jpg.rf.4e7955b1a5fe93831f109bb3553666c6.txt\n","‚úÖ Cleaned BOM from: d83c5b64-dcad-11ef-9634-0242ac1c000c_jpg.rf.3149880b1abb4328d2e67d5bf6b93186.txt\n","‚úÖ Cleaned BOM from: dd5bdade-dcad-11ef-9634-0242ac1c000c_jpg.rf.9e4aaafd2d77e2d942d1b937d2a00157.txt\n","‚úÖ Cleaned BOM from: ecaaf174-dcac-11ef-9634-0242ac1c000c_jpg.rf.5b075f20ec9cf1e386bff5139978f116.txt\n","‚úÖ Cleaned BOM from: e5be7674-dcac-11ef-9634-0242ac1c000c_jpg.rf.496087c4f695bf850cef15ea84394e57.txt\n","‚úÖ Cleaned BOM from: d75cbc66-dcad-11ef-9634-0242ac1c000c_jpg.rf.7fab00cbb1e105b8968025b0b54953ce.txt\n","‚úÖ Cleaned BOM from: d5e9905c-dcad-11ef-9634-0242ac1c000c_jpg.rf.fc41a2b770a1d69342be0a269178bcaf.txt\n","‚úÖ Cleaned BOM from: d5e0c3fa-dcad-11ef-9634-0242ac1c000c_jpg.rf.0a370f28894f06f28de5e108d6060dda.txt\n","‚úÖ Cleaned BOM from: d5c2ea42-dcad-11ef-9634-0242ac1c000c_jpg.rf.39126a9d1d26cf27423b915b072c2ecf.txt\n","‚úÖ Cleaned BOM from: d5c0267c-dcad-11ef-9634-0242ac1c000c_jpg.rf.03c2fb47cc59861ad1c4a7bc9616bf4a.txt\n","‚úÖ Cleaned BOM from: d5bd8c6e-dcad-11ef-9634-0242ac1c000c_jpg.rf.97fe56c6b94d1ac589d63b0aa4aed7f0.txt\n","‚úÖ Cleaned BOM from: cce571f6-dcad-11ef-9634-0242ac1c000c_jpg.rf.48ea2886fb50f2acec52794a3a9ef27f.txt\n","‚úÖ Cleaned BOM from: d09b9c58-dcad-11ef-9634-0242ac1c000c_jpg.rf.b6d9be0e12eaf883749e419497e50c94.txt\n","‚úÖ Cleaned BOM from: ce89afa4-dcad-11ef-9634-0242ac1c000c_jpg.rf.a42139ba03afa8ebc3652285c2027143.txt\n","‚úÖ Cleaned BOM from: c3d916e4-dcad-11ef-9634-0242ac1c000c_jpg.rf.7072d80196d8562f3861db531a7b4732.txt\n","‚úÖ Cleaned BOM from: c38ac584-dcad-11ef-9634-0242ac1c000c_jpg.rf.14ba82cc13222bc190924e83d7b8deb5.txt\n","‚úÖ Cleaned BOM from: c3a2a0d2-dcad-11ef-9634-0242ac1c000c_jpg.rf.b4dc1ef14334998e3b89a5313d4727ee.txt\n","‚úÖ Cleaned BOM from: c425482a-dcad-11ef-9634-0242ac1c000c_jpg.rf.16459913ee928c48fea9dcec1f533a96.txt\n","‚úÖ Cleaned BOM from: c4385c62-dcad-11ef-9634-0242ac1c000c_jpg.rf.3af67f828f064b41139055605f5cc21b.txt\n","‚úÖ Cleaned BOM from: d0757988-dcad-11ef-9634-0242ac1c000c_jpg.rf.ba9dd1b08bd8b8d0ad66118fa216446e.txt\n","‚úÖ Cleaned BOM from: ccd67ea8-dcad-11ef-9634-0242ac1c000c_jpg.rf.a6b14091ecdffb66366dd376f99f9e27.txt\n","‚úÖ Cleaned BOM from: c3848976-dcad-11ef-9634-0242ac1c000c_jpg.rf.d37889d64dc23771cb92b6de98865b13.txt\n","‚úÖ Cleaned BOM from: b9eb5b20-dcac-11ef-9634-0242ac1c000c_jpg.rf.d9afdaf5bf601faf95a9f4a41afd9642.txt\n","‚úÖ Cleaned BOM from: c05cea46-dcac-11ef-9634-0242ac1c000c_jpg.rf.23744e4f849eef081ba2549ae8dcf017.txt\n","‚úÖ Cleaned BOM from: 9bd0c386-dcad-11ef-9634-0242ac1c000c_jpg.rf.c38750b2179305ed8f17def87af74d2e.txt\n","‚úÖ Cleaned BOM from: bc0b24bc-dcac-11ef-9634-0242ac1c000c_jpg.rf.9c82a2e2bb128897a745583d8335aa51.txt\n","‚úÖ Cleaned BOM from: bda08ef6-dcad-11ef-9634-0242ac1c000c_jpg.rf.03a41d2e09eef9b7b108f9ac6e1c38e9.txt\n","‚úÖ Cleaned BOM from: bc9c9230-dcac-11ef-9634-0242ac1c000c_jpg.rf.113dfe8fa5036c745c958fdb6f775753.txt\n","‚úÖ Cleaned BOM from: 9c8fd2b2-dcad-11ef-9634-0242ac1c000c_jpg.rf.fe5b21406b629aa47ea420227157b45e.txt\n","‚úÖ Cleaned BOM from: 924e7d76-dcad-11ef-9634-0242ac1c000c_jpg.rf.f2f308f605830450bfbc996361e73108.txt\n","‚úÖ Cleaned BOM from: 9c8a245c-dcad-11ef-9634-0242ac1c000c_jpg.rf.bce51bdf37c2d692e9e9eb07191588d7.txt\n","‚úÖ Cleaned BOM from: 97be8efe-dcad-11ef-9634-0242ac1c000c_jpg.rf.2c1b2e629af0ba702ce3784022b6e2e4.txt\n","‚úÖ Cleaned BOM from: 977cbf56-dcad-11ef-9634-0242ac1c000c_jpg.rf.cec7b95e384ce4b1be456d2127862e1e.txt\n","‚úÖ Cleaned BOM from: 9bad9a82-dcad-11ef-9634-0242ac1c000c_jpg.rf.fdcd643b30d609c31f484f3b599a1dac.txt\n","‚úÖ Cleaned BOM from: 9bd31dde-dcad-11ef-9634-0242ac1c000c_jpg.rf.d358382b4ab7fa709bd6e6dd01cb41ee.txt\n","‚úÖ Cleaned BOM from: 95f1e9f4-dcad-11ef-9634-0242ac1c000c_jpg.rf.1cd21607d062c889cc9402cc95ca9e59.txt\n","‚úÖ Cleaned BOM from: 9c5aa2ea-dcad-11ef-9634-0242ac1c000c_jpg.rf.c2ca33d71cf7e57209e6eb11430485b1.txt\n","‚úÖ Cleaned BOM from: 962db024-dcad-11ef-9634-0242ac1c000c_jpg.rf.576316807d4cc68df87ed36b247e176d.txt\n","‚úÖ Cleaned BOM from: 906b231a-dcad-11ef-9634-0242ac1c000c_jpg.rf.be32d613ff66da7cb497b240c5b2c393.txt\n","‚úÖ Cleaned BOM from: 8de375a2-dcad-11ef-9634-0242ac1c000c_jpg.rf.eb28637bbe5f56e1ffde96a8e0e22e9d.txt\n","‚úÖ Cleaned BOM from: 904afc5c-dcad-11ef-9634-0242ac1c000c_jpg.rf.b5bb6e0e15894cf17e7809cdac61ab47.txt\n","‚úÖ Cleaned BOM from: 8e116e62-dcad-11ef-9634-0242ac1c000c_jpg.rf.98573edef2de8b57eb6fab39df68a1b8.txt\n","‚úÖ Cleaned BOM from: 8ee43946-dcad-11ef-9634-0242ac1c000c_jpg.rf.62af25dfe6ce64a32f6919511f2b5fb8.txt\n","‚úÖ Cleaned BOM from: 8edc245e-dcad-11ef-9634-0242ac1c000c_jpg.rf.73f673008deca271bdbe0103c8d5afb6.txt\n","‚úÖ Cleaned BOM from: 8de0c618-dcad-11ef-9634-0242ac1c000c_jpg.rf.f2c8ec2cf195cbfccb90f74b59fbfd64.txt\n","‚úÖ Cleaned BOM from: 8d2e2fe4-dcad-11ef-9634-0242ac1c000c_jpg.rf.4363838265b6f346785079c299cfab73.txt\n","‚úÖ Cleaned BOM from: 8d6464a6-dcad-11ef-9634-0242ac1c000c_jpg.rf.7e532a9f573597ae649d8c38ffd1f878.txt\n","‚úÖ Cleaned BOM from: 7c5c1992-dcad-11ef-9634-0242ac1c000c_jpg.rf.1f7094ad6366aa9d6aad6fab65bcbfd8.txt\n","‚úÖ Cleaned BOM from: 739c5c54-dcad-11ef-9634-0242ac1c000c_jpg.rf.46c4af1d41b362b43ae0e3942cd514fb.txt\n","‚úÖ Cleaned BOM from: 85055ff4-dcad-11ef-9634-0242ac1c000c_jpg.rf.f5b8bb68f0420feee05822e832374c9c.txt\n","‚úÖ Cleaned BOM from: 799b2842-dcad-11ef-9634-0242ac1c000c_jpg.rf.6f328ee25cb304ea8da7df955d51bcd2.txt\n","‚úÖ Cleaned BOM from: 797ad9e8-dcad-11ef-9634-0242ac1c000c_jpg.rf.0723958619c82661dc0a9ac612707161.txt\n","‚úÖ Cleaned BOM from: 8d3f0986-dcad-11ef-9634-0242ac1c000c_jpg.rf.4ba96cbadb608d4b33cd253f168b69f7.txt\n","‚úÖ Cleaned BOM from: 8d5c10b2-dcad-11ef-9634-0242ac1c000c_jpg.rf.7babb7e1b9771f484a3185d2ff2b6cdf.txt\n","‚úÖ Cleaned BOM from: 8c10315c-dcad-11ef-9634-0242ac1c000c_jpg.rf.2fd58ad55f9d5d733b1ddee10deafb7b.txt\n","‚úÖ Cleaned BOM from: 85e55118-dcad-11ef-9634-0242ac1c000c_jpg.rf.4350aad1a7e9ea79034d109d81e4eaac.txt\n","‚úÖ Cleaned BOM from: 684beb3a-dcad-11ef-9634-0242ac1c000c_jpg.rf.fb34e2ac74a257ea685b6de42ce20475.txt\n","‚úÖ Cleaned BOM from: 688ac2f6-dcad-11ef-9634-0242ac1c000c_jpg.rf.4ac63003749cd0a9aa84ac0cdaf7ea8d.txt\n","‚úÖ Cleaned BOM from: 674cb584-dcad-11ef-9634-0242ac1c000c_jpg.rf.df13c34d082d0c1442e281216901ae16.txt\n","‚úÖ Cleaned BOM from: 686e2a10-dcad-11ef-9634-0242ac1c000c_jpg.rf.c06d05c557a54dc1d2c7da28e20a02a8.txt\n","‚úÖ Cleaned BOM from: 685f54fe-dcad-11ef-9634-0242ac1c000c_jpg.rf.4dc883292060e3074b6230bbeef516c3.txt\n","‚úÖ Cleaned BOM from: 673ba3fc-dcad-11ef-9634-0242ac1c000c_jpg.rf.774df0a64897f32dfc9725109ad25466.txt\n","‚úÖ Cleaned BOM from: 670c8374-dcad-11ef-9634-0242ac1c000c_jpg.rf.dc03273cd1b37c05566ff7e6a3ee0c0d.txt\n","‚úÖ Cleaned BOM from: 672ea648-dcad-11ef-9634-0242ac1c000c_jpg.rf.d58236e7a11b4e055482de903873983f.txt\n","‚úÖ Cleaned BOM from: 664ef6e2-dcad-11ef-9634-0242ac1c000c_jpg.rf.1485102e99b9a6350577220b454e8261.txt\n","‚úÖ Cleaned BOM from: 667e4d8e-dcad-11ef-9634-0242ac1c000c_jpg.rf.fcd6c0684e31d92a970cc4fb33598ec3.txt\n","‚úÖ Cleaned BOM from: 5f512dc4-dcad-11ef-9634-0242ac1c000c_jpg.rf.0ded30dbe87caac305053c420f3a91f1.txt\n","‚úÖ Cleaned BOM from: 1ea3f4f0-dcad-11ef-9634-0242ac1c000c_jpg.rf.18d97154d97bc988670bd25ba4299cb3.txt\n","‚úÖ Cleaned BOM from: 5edd1498-dcad-11ef-9634-0242ac1c000c_jpg.rf.fb5aecfd21d37c4bd95a78bdc08b9e4d.txt\n","‚úÖ Cleaned BOM from: 5f2e0c9a-dcad-11ef-9634-0242ac1c000c_jpg.rf.1c6bc1508e666798f3556cc204d099de.txt\n","‚úÖ Cleaned BOM from: 337b5d96-dcad-11ef-9634-0242ac1c000c_jpg.rf.e65c6a1440ea40466d246aaae17244ac.txt\n","‚úÖ Cleaned BOM from: 663d6a4e-dcad-11ef-9634-0242ac1c000c_jpg.rf.d85c07c3ac9935a0b236824f3fae0290.txt\n","‚úÖ Cleaned BOM from: 5fd2dc8e-dcad-11ef-9634-0242ac1c000c_jpg.rf.81c453481c81875397678c82bf87070f.txt\n","‚úÖ Cleaned BOM from: 5f58e820-dcad-11ef-9634-0242ac1c000c_jpg.rf.e61291ae665cbba13a9553bbdbb45837.txt\n","‚úÖ Cleaned BOM from: 1e5bb046-dcad-11ef-9634-0242ac1c000c_jpg.rf.0819c72e5566c1ff12d5969b5433a5d2.txt\n","‚úÖ Cleaned BOM from: 1dc53c4c-dcad-11ef-9634-0242ac1c000c_jpg.rf.c0f234b6ee85028053a88d14e4df52df.txt\n","üöÄ All label files are cleaned and ready!\n"]}]},{"cell_type":"markdown","source":["# **Loading Model**"],"metadata":{"id":"VenkdIlH_vz9"}},{"cell_type":"code","source":["model = YOLO(\"yolov8n.pt\")"],"metadata":{"id":"C0S0KK1oxf-2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"oXDW4lfJ_759"}},{"cell_type":"code","source":["import csv\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","log_file = \"/content/drive/MyDrive/Car Theft Model/Logs/Accuracy Logs.csv\"\n","\n","with open(log_file, mode=\"w\", newline=\"\") as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Epoch\", \"Box Loss\", \"Class Loss\", \"DFL Loss\", \"mAP50\", \"mAP50-95\"])\n","\n","# Training Config\n","results = model.train(\n","    data=yaml_path,\n","    epochs=50,\n","    batch=32,\n","    imgsz=640,\n","    lr0=0.001,\n","    weight_decay=0.0005,\n","    momentum=0.937,\n","    augment=True\n",")\n","\n","print(\"Available attributes in results:\", dir(results))\n","if hasattr(results, 'results_dict'):\n","    print(\"Keys in results_dict:\", results.results_dict.keys())\n","\n","# Training History Retrieval\n","try:\n","    if hasattr(results, 'training_results'):\n","        print(\"Using training_results attribute\")\n","        for epoch, data in enumerate(results.training_results, 1):\n","            box_loss = data.get('box_loss', 0)\n","            cls_loss = data.get('cls_loss', 0)\n","            dfl_loss = data.get('dfl_loss', 0)\n","            map50 = data.get('map50', 0)\n","            map50_95 = data.get('map', 0)\n","\n","            with open(log_file, mode=\"a\", newline=\"\") as file:\n","                writer = csv.writer(file)\n","                writer.writerow([epoch, box_loss, cls_loss, dfl_loss, map50, map50_95])\n","\n","            print(f\"Logged epoch {epoch} metrics\")\n","\n","    elif hasattr(results, 'save_dir'):\n","        print(\"Using CSV files from save directory\")\n","        import pandas as pd\n","        results_csv = str(results.save_dir / 'results.csv')\n","\n","        if os.path.exists(results_csv):\n","            df = pd.read_csv(results_csv)\n","            print(f\"Columns in results.csv: {df.columns.tolist()}\")\n","\n","            for index, row in df.iterrows():\n","                epoch = row.get('epoch', index + 1)\n","                box_loss = row.get('box_loss', 0)\n","                cls_loss = row.get('cls_loss', 0)\n","                dfl_loss = row.get('dfl_loss', 0)\n","                map50 = row.get('metrics/mAP50(B)', 0)\n","                map50_95 = row.get('metrics/mAP50-95(B)', 0)\n","\n","                with open(log_file, mode=\"a\", newline=\"\") as file:\n","                    writer = csv.writer(file)\n","                    writer.writerow([epoch, box_loss, cls_loss, dfl_loss, map50, map50_95])\n","\n","                print(f\"Logged epoch {epoch} metrics from results.csv\")\n","\n","    else:\n","        print(\"Using final results dict\")\n","        results_dict = results.results_dict\n","        print(f\"Keys in results_dict: {results_dict.keys()}\")\n","\n","        for epoch in range(1, 3):\n","            map50 = results_dict.get('metrics/mAP50(B)', 0)\n","            map50_95 = results_dict.get('metrics/mAP50-95(B)', 0)\n","\n","            box_loss = 0\n","            cls_loss = 0\n","            dfl_loss = 0\n","\n","            with open(log_file, mode=\"a\", newline=\"\") as file:\n","                writer = csv.writer(file)\n","                writer.writerow([epoch, box_loss, cls_loss, dfl_loss, map50, map50_95])\n","\n","            print(f\"Logged epoch {epoch} metrics (final values)\")\n","\n","except Exception as e:\n","    print(f\"Error extracting training logs: {str(e)}\")\n","\n","    print(\"\\nDumping all available information for debugging:\")\n","    for attr in dir(results):\n","        if not attr.startswith('__'):\n","            try:\n","                value = getattr(results, attr)\n","                print(f\"{attr}: {type(value)}\")\n","                if isinstance(value, dict):\n","                    print(f\"  Dictionary keys: {value.keys()}\")\n","            except:\n","                print(f\"{attr}: Unable to access\")\n","\n","model.save(\"/content/drive/MyDrive/Car Theft Model/Models/yolov8n_75e_final.pt\")\n","print(\"Model saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSlRd-CSxwAQ","outputId":"b86985a0-4171-4f35-d795-6c29de802795","executionInfo":{"status":"ok","timestamp":1743035429165,"user_tz":-360,"elapsed":1067149,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.96 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Colab Notebooks/yolov8n_75e_f.pt, data=/content/drive/MyDrive/Colab Notebooks/Dataset/data.yaml, epochs=50, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 70/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1osQbHLpARn1Inx8Jbr8gzOCF4mRK3u3v/Colab Notebooks/Dataset/train/labels.cache... 848 images, 15 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 848/848 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1osQbHLpARn1Inx8Jbr8gzOCF4mRK3u3v/Colab Notebooks/Dataset/valid/labels.cache... 81 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train3\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/50       4.2G        2.1      1.785      2.175         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.805      0.139      0.183     0.0764\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/50      4.96G      1.189     0.9282      1.544         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.76it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.638      0.228      0.335      0.145\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/50      4.96G      1.005     0.7633      1.384         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.95it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.627      0.456      0.596       0.33\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/50      4.96G      1.022     0.7582      1.371         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.894      0.745      0.876      0.501\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/50      4.97G      0.964     0.7424       1.34         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.887      0.911       0.93      0.637\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/50      4.97G     0.9399     0.6934      1.326         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.959      0.886       0.95      0.681\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/50      4.97G     0.9303     0.6857      1.317         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.88it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.903      0.949      0.938      0.728\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/50      4.97G      0.924     0.6856       1.32         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.946      0.911      0.936      0.682\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/50      4.97G     0.8658      0.634      1.259         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.899      0.905      0.955      0.682\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/50      4.98G     0.8608     0.6326      1.263         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:20<00:00,  1.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.947      0.949      0.961      0.749\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/50      4.98G     0.8383     0.6053      1.244         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.944       0.81      0.912      0.661\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/50      4.99G     0.8526     0.6092      1.236         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.858      0.842      0.879      0.658\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/50         5G     0.8343     0.5884      1.229         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.946      0.924      0.963      0.738\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/50         5G     0.8084     0.5762      1.227         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.902      0.949      0.947      0.767\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/50         5G     0.7992     0.5598      1.228         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.925      0.975      0.958      0.746\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/50      5.01G     0.8055     0.5719      1.216         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.957      0.924      0.958      0.724\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/50      5.02G     0.7862     0.5581      1.219         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.83it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.96      0.937      0.967      0.801\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/50      5.02G     0.7585     0.5296      1.194         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.95      0.961      0.976      0.795\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/50      5.02G     0.7799      0.543        1.2         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.942      0.924      0.965      0.796\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/50      5.03G     0.7644     0.5229      1.192         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.962      0.961      0.958      0.787\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/50      5.04G     0.7437     0.5075       1.17         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.972      0.962      0.968      0.787\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/50      5.05G     0.7664     0.5215      1.189         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.946      0.899      0.955      0.747\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/50      5.05G     0.7338     0.5185      1.166         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.973      0.962       0.96      0.777\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/50      5.07G     0.7357     0.5101      1.171         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.962      0.974      0.969      0.771\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/50      5.07G     0.7129     0.4982      1.178         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.75it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.927      0.969      0.962      0.806\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/50      5.09G     0.7137     0.4823      1.165         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.95      0.958      0.968      0.779\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/50      5.09G      0.702     0.4765      1.157         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.962       0.96      0.976      0.792\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/50      5.09G     0.7255     0.4883      1.161         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.95      0.961      0.979      0.803\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/50      5.09G     0.7114     0.4688      1.167         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.938      0.958      0.964      0.797\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/50      5.09G     0.6811     0.4397      1.136         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.97      0.937      0.969      0.817\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      31/50      5.09G     0.6619     0.4494      1.133         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.73it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.926      0.975      0.968       0.81\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      32/50      5.09G     0.6755     0.4725      1.131         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.24s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.95      0.962       0.98      0.819\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      33/50      5.09G     0.6619     0.4457      1.129         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.71it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.95      0.958      0.976      0.791\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      34/50      5.09G     0.6672     0.4385      1.124         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.958      0.949      0.977      0.822\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      35/50      5.09G     0.6506      0.425      1.127         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.38s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.96      0.949      0.971      0.797\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      36/50      5.09G      0.667     0.4327      1.125         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.974      0.949      0.977      0.817\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      37/50      5.09G     0.6504     0.4278      1.113         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.96it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.961      0.946      0.965      0.792\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      38/50      5.09G     0.6276      0.408      1.096         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.947      0.937      0.973      0.813\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      39/50      5.09G     0.6432     0.4063      1.115         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:19<00:00,  1.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.961      0.975      0.971      0.821\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      40/50      5.09G     0.6221     0.4081      1.116         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:18<00:00,  1.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.83it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.961      0.949      0.964      0.818\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      41/50      5.09G     0.5313     0.3399      1.104         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:20<00:00,  1.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.934      0.949       0.97      0.806\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      42/50      5.09G     0.5078      0.285      1.091         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.96      0.962      0.976      0.807\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      43/50      5.09G     0.5004     0.2805      1.063         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.938      0.961      0.964      0.807\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      44/50      5.09G     0.4904     0.2782      1.072         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.938      0.957      0.962      0.802\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      45/50      5.09G     0.4767     0.2755      1.067         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79       0.95      0.972      0.975      0.821\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      46/50      5.09G     0.4776     0.2641      1.057         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.78it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.938      0.962      0.964      0.824\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      47/50      5.09G     0.4672      0.258      1.044         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.937      0.962      0.964      0.815\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      48/50      5.09G     0.4579     0.2579      1.039         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:16<00:00,  1.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.938      0.961      0.963      0.826\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      49/50      5.09G     0.4481     0.2501      1.022         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:15<00:00,  1.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.937      0.962      0.962       0.82\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      50/50      5.09G     0.4503     0.2511      1.034         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:17<00:00,  1.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.937      0.962      0.962      0.818\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","50 epochs completed in 0.292 hours.\n","Optimizer stripped from runs/detect/train3/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train3/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train3/weights/best.pt...\n","Ultralytics 8.3.96 üöÄ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         81         79      0.951      0.975      0.972      0.852\n","Speed: 0.3ms preprocess, 8.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train3\u001b[0m\n","Available attributes in results: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'ap_class_index', 'box', 'class_result', 'confusion_matrix', 'curves', 'curves_results', 'fitness', 'keys', 'maps', 'mean_results', 'names', 'plot', 'process', 'results_dict', 'save_dir', 'speed', 'task']\n","Keys in results_dict: dict_keys(['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'fitness'])\n","Using CSV files from save directory\n","Columns in results.csv: ['epoch', 'time', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n","Logged epoch 1.0 metrics from results.csv\n","Logged epoch 2.0 metrics from results.csv\n","Logged epoch 3.0 metrics from results.csv\n","Logged epoch 4.0 metrics from results.csv\n","Logged epoch 5.0 metrics from results.csv\n","Logged epoch 6.0 metrics from results.csv\n","Logged epoch 7.0 metrics from results.csv\n","Logged epoch 8.0 metrics from results.csv\n","Logged epoch 9.0 metrics from results.csv\n","Logged epoch 10.0 metrics from results.csv\n","Logged epoch 11.0 metrics from results.csv\n","Logged epoch 12.0 metrics from results.csv\n","Logged epoch 13.0 metrics from results.csv\n","Logged epoch 14.0 metrics from results.csv\n","Logged epoch 15.0 metrics from results.csv\n","Logged epoch 16.0 metrics from results.csv\n","Logged epoch 17.0 metrics from results.csv\n","Logged epoch 18.0 metrics from results.csv\n","Logged epoch 19.0 metrics from results.csv\n","Logged epoch 20.0 metrics from results.csv\n","Logged epoch 21.0 metrics from results.csv\n","Logged epoch 22.0 metrics from results.csv\n","Logged epoch 23.0 metrics from results.csv\n","Logged epoch 24.0 metrics from results.csv\n","Logged epoch 25.0 metrics from results.csv\n","Logged epoch 26.0 metrics from results.csv\n","Logged epoch 27.0 metrics from results.csv\n","Logged epoch 28.0 metrics from results.csv\n","Logged epoch 29.0 metrics from results.csv\n","Logged epoch 30.0 metrics from results.csv\n","Logged epoch 31.0 metrics from results.csv\n","Logged epoch 32.0 metrics from results.csv\n","Logged epoch 33.0 metrics from results.csv\n","Logged epoch 34.0 metrics from results.csv\n","Logged epoch 35.0 metrics from results.csv\n","Logged epoch 36.0 metrics from results.csv\n","Logged epoch 37.0 metrics from results.csv\n","Logged epoch 38.0 metrics from results.csv\n","Logged epoch 39.0 metrics from results.csv\n","Logged epoch 40.0 metrics from results.csv\n","Logged epoch 41.0 metrics from results.csv\n","Logged epoch 42.0 metrics from results.csv\n","Logged epoch 43.0 metrics from results.csv\n","Logged epoch 44.0 metrics from results.csv\n","Logged epoch 45.0 metrics from results.csv\n","Logged epoch 46.0 metrics from results.csv\n","Logged epoch 47.0 metrics from results.csv\n","Logged epoch 48.0 metrics from results.csv\n","Logged epoch 49.0 metrics from results.csv\n","Logged epoch 50.0 metrics from results.csv\n","Model saved successfully!\n"]}]},{"cell_type":"markdown","source":["# **Visualization**"],"metadata":{"id":"I8KfRlYQAnOO"}},{"cell_type":"code","source":["import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","import numpy as np\n","from scipy.signal import savgol_filter\n","\n","log_file = \"/content/drive/MyDrive/Car Theft Model/Logs/Accuracy Logs.csv\"\n","df = pd.read_csv(log_file)\n","\n","df['training_progress'] = df.index / len(df) * 100\n","df['convergence_ratio'] = df['mAP50-95'] / df['mAP50']\n","df['plateau_detection'] = df['mAP50'].diff().rolling(window=5).mean()\n","\n","df['mAP50_smooth'] = savgol_filter(df['mAP50'], window_length=7, polyorder=2) if len(df) > 7 else df['mAP50']\n","df['mAP50-95_smooth'] = savgol_filter(df['mAP50-95'], window_length=7, polyorder=2) if len(df) > 7 else df['mAP50-95']\n","\n","\n","fig = make_subplots(\n","    rows=2, cols=2,\n","    subplot_titles=(\n","        \"Primary Metrics Performance\",\n","        \"Performance Improvement from Baseline\",\n","        \"Convergence Analysis\",\n","        \"Learning Stability\"\n","    ),\n","    specs=[\n","        [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n","        [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]\n","    ],\n","    vertical_spacing=0.12,\n","    horizontal_spacing=0.08\n",")\n","\n","colors = {\n","    'mAP50': '#1f77b4',         # Blue\n","    'mAP50-95': '#ff7f0e',      # Orange\n","    'background': '#F8F9FA',    # Light gray background\n","    'grid': '#E4E4E4',          # Grid color\n","    'annotation': '#2C3E50',    # Dark blue-gray for annotations\n","    'trend': '#2ecc71',         # Green for trends\n","    'area': 'rgba(52, 152, 219, 0.2)'  # Light blue for area\n","}\n","\n","expected_min = 0.85\n","expected_max = 0.95\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=[expected_max] * len(df),\n","        mode='lines',\n","        line=dict(width=0),\n","        showlegend=False,\n","        hoverinfo='skip'\n","    ),\n","    row=1, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=[expected_min] * len(df),\n","        mode='lines',\n","        line=dict(width=0),\n","        fill='tonexty',\n","        fillcolor='rgba(144, 238, 144, 0.2)',  # Light green\n","        showlegend=True,\n","        name=\"Expected Range\",\n","        hoverinfo='skip'\n","    ),\n","    row=1, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50\"],\n","        mode=\"lines+markers\",\n","        name=\"mAP50\",\n","        line=dict(color=colors['mAP50'], width=2.5, shape='spline'),\n","        marker=dict(symbol=\"triangle-up\", size=9, color=colors['mAP50'], line=dict(width=1, color='white')),\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>mAP50:</b> %{y:.4f}\"\n","    ),\n","    row=1, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50-95\"],\n","        mode=\"lines+markers\",\n","        name=\"mAP50-95\",\n","        line=dict(color=colors['mAP50-95'], width=2.5, shape='spline'),\n","        marker=dict(symbol=\"x\", size=9, color=colors['mAP50-95'], line=dict(width=1, color='white')),\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>mAP50-95:</b> %{y:.4f}\"\n","    ),\n","    row=1, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50_smooth\"],\n","        mode=\"lines\",\n","        line=dict(color=colors['mAP50'], width=1.5, dash='dot'),\n","        showlegend=False,\n","        hoverinfo='skip'\n","    ),\n","    row=1, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50-95_smooth\"],\n","        mode=\"lines\",\n","        line=dict(color=colors['mAP50-95'], width=1.5, dash='dot'),\n","        showlegend=False,\n","        hoverinfo='skip'\n","    ),\n","    row=1, col=1\n",")\n","\n","df['mAP50_rel_improvement'] = (df['mAP50'] / df['mAP50'].iloc[0] - 1) * 100\n","df['mAP50-95_rel_improvement'] = (df['mAP50-95'] / df['mAP50-95'].iloc[0] - 1) * 100\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50_rel_improvement\"],\n","        mode=\"lines\",\n","        name=\"mAP50 Improvement\",\n","        line=dict(color=colors['mAP50'], width=2, shape='spline'),\n","        fill='tozeroy',\n","        fillcolor=f'rgba(31, 119, 180, 0.3)',\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>Improvement:</b> %{y:.2f}%\"\n","    ),\n","    row=1, col=2\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50-95_rel_improvement\"],\n","        mode=\"lines\",\n","        name=\"mAP50-95 Improvement\",\n","        line=dict(color=colors['mAP50-95'], width=2, shape='spline'),\n","        fill='tozeroy',\n","        fillcolor=f'rgba(255, 127, 14, 0.3)',\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>Improvement:</b> %{y:.2f}%\"\n","    ),\n","    row=1, col=2\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"convergence_ratio\"],\n","        mode=\"lines+markers\",\n","        name=\"Convergence Ratio\",\n","        line=dict(color=\"#9b59b6\", width=2.5, shape='spline'),  # Purple\n","        marker=dict(size=7, symbol=\"circle\", color=\"#9b59b6\", line=dict(width=1, color='white')),\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>mAP50-95/mAP50:</b> %{y:.4f}\"\n","    ),\n","    row=2, col=1\n",")\n","\n","ideal_convergence = 1.0\n","fig.add_trace(\n","    go.Scatter(\n","        x=[df[\"Epoch\"].min(), df[\"Epoch\"].max()],\n","        y=[ideal_convergence, ideal_convergence],\n","        mode=\"lines\",\n","        line=dict(color=\"rgba(155, 89, 182, 0.5)\", width=1.5, dash='dash'),\n","        name=\"Ideal Convergence\",\n","        hoverinfo='skip'\n","    ),\n","    row=2, col=1\n",")\n","\n","df['mAP50_change'] = df['mAP50'].diff().fillna(0)\n","df['mAP50-95_change'] = df['mAP50-95'].diff().fillna(0)\n","\n","df['mAP50_change_smooth'] = savgol_filter(df['mAP50_change'], window_length=5, polyorder=1) if len(df) > 5 else df['mAP50_change']\n","df['mAP50-95_change_smooth'] = savgol_filter(df['mAP50-95_change'], window_length=5, polyorder=1) if len(df) > 5 else df['mAP50-95_change']\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50_change_smooth\"],\n","        mode=\"lines\",\n","        name=\"mAP50 Rate of Change\",\n","        line=dict(color=colors['mAP50'], width=2, shape='spline'),\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>Change:</b> %{y:.4f}\"\n","    ),\n","    row=2, col=2\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=df[\"Epoch\"],\n","        y=df[\"mAP50-95_change_smooth\"],\n","        mode=\"lines\",\n","        name=\"mAP50-95 Rate of Change\",\n","        line=dict(color=colors['mAP50-95'], width=2, shape='spline'),\n","        hovertemplate=\"<b>Epoch:</b> %{x}<br><b>Change:</b> %{y:.4f}\"\n","    ),\n","    row=2, col=2\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=[df[\"Epoch\"].min(), df[\"Epoch\"].max()],\n","        y=[0, 0],\n","        mode=\"lines\",\n","        line=dict(color=\"rgba(0, 0, 0, 0.3)\", width=1.5, dash='dash'),\n","        showlegend=False,\n","        hoverinfo='skip'\n","    ),\n","    row=2, col=2\n",")\n","\n","# ANNOTATIONS\n","best_map50_epoch = df['mAP50'].idxmax()\n","best_map50_95_epoch = df['mAP50-95'].idxmax()\n","first_plateau_epoch = df[df['plateau_detection'].abs() < 0.001].index[3] if len(df[df['plateau_detection'].abs() < 0.001]) > 3 else None\n","highest_improvement_epoch = df['mAP50-95_rel_improvement'].idxmax()\n","\n","fig.add_annotation(\n","    x=df['Epoch'].iloc[best_map50_epoch],\n","    y=df['mAP50'].iloc[best_map50_epoch],\n","    text=f\"Best mAP50: {df['mAP50'].iloc[best_map50_epoch]:.4f}\",\n","    showarrow=True,\n","    arrowhead=2,\n","    arrowsize=1,\n","    arrowwidth=2,\n","    arrowcolor=colors['mAP50'],\n","    font=dict(color=\"white\", size=11),\n","    bordercolor=colors['mAP50'],\n","    bgcolor=colors['mAP50'],\n","    borderwidth=1,\n","    borderpad=4,\n","    row=1, col=1\n",")\n","\n","fig.add_annotation(\n","    x=df['Epoch'].iloc[best_map50_95_epoch],\n","    y=df['mAP50-95'].iloc[best_map50_95_epoch],\n","    text=f\"Best mAP50-95: {df['mAP50-95'].iloc[best_map50_95_epoch]:.4f}\",\n","    showarrow=True,\n","    arrowhead=2,\n","    arrowsize=1,\n","    arrowwidth=2,\n","    arrowcolor=colors['mAP50-95'],\n","    font=dict(color=\"white\", size=11),\n","    bordercolor=colors['mAP50-95'],\n","    bgcolor=colors['mAP50-95'],\n","    borderwidth=1,\n","    borderpad=4,\n","    row=1, col=1\n",")\n","\n","fig.add_annotation(\n","    x=df['Epoch'].iloc[highest_improvement_epoch],\n","    y=df['mAP50-95_rel_improvement'].iloc[highest_improvement_epoch],\n","    text=f\"Highest Improvement: {df['mAP50-95_rel_improvement'].iloc[highest_improvement_epoch]:.1f}%\",\n","    showarrow=True,\n","    arrowhead=2,\n","    arrowsize=1,\n","    arrowwidth=2,\n","    arrowcolor=colors['mAP50-95'],\n","    font=dict(color=\"white\", size=11),\n","    bordercolor=colors['mAP50-95'],\n","    bgcolor=colors['mAP50-95'],\n","    borderwidth=1,\n","    borderpad=4,\n","    row=1, col=2\n",")\n","\n","if first_plateau_epoch:\n","    fig.add_annotation(\n","        x=df['Epoch'].iloc[first_plateau_epoch],\n","        y=df['mAP50_change_smooth'].iloc[first_plateau_epoch],\n","        text=\"Training Plateau Detected\",\n","        showarrow=True,\n","        arrowhead=2,\n","        arrowsize=1,\n","        arrowwidth=2,\n","        arrowcolor=\"#e74c3c\",  # Red\n","        font=dict(color=\"white\", size=11),\n","        bordercolor=\"#e74c3c\",\n","        bgcolor=\"#e74c3c\",\n","        borderwidth=1,\n","        borderpad=4,\n","        row=2, col=2\n","    )\n","\n","final_map50 = df['mAP50'].iloc[-1]\n","final_map50_95 = df['mAP50-95'].iloc[-1]\n","evaluation_text = (\n","    f\"<b>Model Performance Summary</b><br>\" +\n","    f\"Final mAP50: {final_map50:.4f}<br>\" +\n","    f\"Final mAP50-95: {final_map50_95:.4f}<br>\" +\n","    f\"Improvement: {df['mAP50_rel_improvement'].iloc[-1]:.1f}% & {df['mAP50-95_rel_improvement'].iloc[-1]:.1f}%<br>\" +\n","    f\"Convergence: {(final_map50_95/final_map50*100):.1f}%\"\n",")\n","\n","fig.add_annotation(\n","    x=0.5, y=1.18,\n","    xref=\"paper\", yref=\"paper\",\n","    text=evaluation_text,\n","    showarrow=False,\n","    font=dict(size=14),\n","    align=\"center\",\n","    bgcolor=\"rgba(255, 255, 255, 0.9)\",\n","    bordercolor=\"#2C3E50\",\n","    borderwidth=1,\n","    borderpad=6\n",")\n","\n","fig.update_layout(\n","    title=dict(\n","        text=\"Model's Performance Analytics During Training(Nano)\",\n","        font=dict(size=22, color=\"#2C3E50\", family=\"Arial, sans-serif\"),\n","        x=0.5,\n","        y=0.98\n","    ),\n","    template=\"plotly_white\",\n","    paper_bgcolor=colors['background'],\n","    plot_bgcolor=colors['background'],\n","    legend=dict(\n","        orientation=\"h\",\n","        yanchor=\"bottom\",\n","        y=-0.15,\n","        xanchor=\"center\",\n","        x=0.5,\n","        bgcolor=\"rgba(255, 255, 255, 0.8)\",\n","        bordercolor=\"#E4E4E4\",\n","        borderwidth=1,\n","        font=dict(family=\"Arial, sans-serif\", size=12, color=\"#2C3E50\")\n","    ),\n","    height=900,\n","    width=1200,\n","    margin=dict(l=80, r=80, t=180, b=100),\n","    hovermode=\"x unified\",\n","    hoverlabel=dict(\n","        bgcolor=\"white\",\n","        font_size=12,\n","        font_family=\"Arial, sans-serif\"\n","    )\n",")\n","\n","for row in [1, 2]:\n","    for col in [1, 2]:\n","        fig.update_xaxes(\n","            title_text=\"Epochs\",\n","            row=row, col=col,\n","            gridcolor=colors['grid'],\n","            title_font=dict(size=13, family=\"Arial, sans-serif\", color=\"#2C3E50\"),\n","            tickfont=dict(size=11, family=\"Arial, sans-serif\", color=\"#2C3E50\"),\n","            showline=True,\n","            linewidth=2,\n","            linecolor=colors['grid'],\n","            zeroline=False\n","        )\n","\n","        fig.update_yaxes(\n","            gridcolor=colors['grid'],\n","            title_font=dict(size=13, family=\"Arial, sans-serif\", color=\"#2C3E50\"),\n","            tickfont=dict(size=11, family=\"Arial, sans-serif\", color=\"#2C3E50\"),\n","            showline=True,\n","            linewidth=2,\n","            linecolor=colors['grid'],\n","            zeroline=False\n","        )\n","\n","fig.update_yaxes(title_text=\"Performance (mAP)\", row=1, col=1, range=[0.65, 1.0])\n","fig.update_yaxes(title_text=\"Improvement from Baseline (%)\", row=1, col=2)\n","fig.update_yaxes(title_text=\"Convergence Ratio (mAP50-95/mAP50)\", row=2, col=1)\n","fig.update_yaxes(title_text=\"Rate of Change\", row=2, col=2)\n","\n","fig.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cFzLFGYrUNqL","executionInfo":{"status":"error","timestamp":1743038918634,"user_tz":-360,"elapsed":620,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"2881a50c-b7bc-4cbe-82ff-d4becc50c245"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"97d9b1fb-73a9-4862-82ad-be460515a019\" class=\"plotly-graph-div\" style=\"height:900px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"97d9b1fb-73a9-4862-82ad-be460515a019\")) {                    Plotly.newPlot(                        \"97d9b1fb-73a9-4862-82ad-be460515a019\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"width\":0},\"mode\":\"lines\",\"showlegend\":false,\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95,0.95],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"fill\":\"tonexty\",\"fillcolor\":\"rgba(144, 238, 144, 0.2)\",\"hoverinfo\":\"skip\",\"line\":{\"width\":0},\"mode\":\"lines\",\"name\":\"Expected Range\",\"showlegend\":true,\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85,0.85],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003emAP50:\\u003c\\u002fb\\u003e %{y:.4f}\",\"line\":{\"color\":\"#1f77b4\",\"shape\":\"spline\",\"width\":2.5},\"marker\":{\"color\":\"#1f77b4\",\"line\":{\"color\":\"white\",\"width\":1},\"size\":9,\"symbol\":\"triangle-up\"},\"mode\":\"lines+markers\",\"name\":\"mAP50\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.18331,0.33535,0.59637,0.87573,0.92958,0.94978,0.93827,0.93595,0.95458,0.96089,0.9119,0.87912,0.96336,0.94686,0.95761,0.95842,0.96729,0.97596,0.96519,0.95772,0.96777,0.95527,0.95984,0.96901,0.96245,0.96825,0.97597,0.97904,0.96419,0.96883,0.96823,0.98049,0.97636,0.97696,0.97128,0.9769,0.96488,0.97318,0.97111,0.96428,0.96952,0.97552,0.96428,0.96233,0.97482,0.96351,0.96436,0.96313,0.96246,0.96182],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003emAP50-95:\\u003c\\u002fb\\u003e %{y:.4f}\",\"line\":{\"color\":\"#ff7f0e\",\"shape\":\"spline\",\"width\":2.5},\"marker\":{\"color\":\"#ff7f0e\",\"line\":{\"color\":\"white\",\"width\":1},\"size\":9,\"symbol\":\"x\"},\"mode\":\"lines+markers\",\"name\":\"mAP50-95\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.07641,0.14462,0.3302,0.50108,0.63712,0.68116,0.7277,0.68173,0.68192,0.74918,0.66131,0.65778,0.73776,0.76668,0.74562,0.72441,0.80077,0.79526,0.79571,0.78701,0.78707,0.74681,0.77733,0.771,0.80649,0.7785,0.79208,0.80317,0.7967,0.81748,0.80963,0.81892,0.79088,0.8216,0.79699,0.81672,0.79185,0.81321,0.82058,0.8183,0.80565,0.80669,0.80667,0.80158,0.82057,0.82429,0.81515,0.82625,0.82043,0.81809],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"#1f77b4\",\"dash\":\"dot\",\"width\":1.5},\"mode\":\"lines\",\"showlegend\":false,\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.12968785714285666,0.41355928571428546,0.638552857142857,0.8046685714285721,0.9295923809523818,0.9613666666666675,0.9457861904761914,0.9503714285714295,0.9502766666666677,0.9317647619047629,0.924360000000001,0.9192509523809533,0.9271100000000008,0.9480038095238105,0.9627019047619056,0.9604619047619057,0.9684071428571438,0.9678219047619057,0.9683909523809533,0.9638680952380962,0.95892761904762,0.9608314285714296,0.9620609523809533,0.9618995238095247,0.9666438095238106,0.9716361904761914,0.972370000000001,0.9735295238095247,0.9700795238095247,0.9690600000000009,0.97062761904762,0.9760666666666675,0.976490000000001,0.9776433333333343,0.9732619047619058,0.9719400000000009,0.9713966666666676,0.9700066666666676,0.9676614285714296,0.9705485714285724,0.9695519047619057,0.9675909523809534,0.9692619047619058,0.9676304761904772,0.9660666666666676,0.9667880952380962,0.9654238095238104,0.9642750000000001,0.9627307142857144,0.9607909523809526],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"#ff7f0e\",\"dash\":\"dot\",\"width\":1.5},\"mode\":\"lines\",\"showlegend\":false,\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.032690476190475964,0.2044792857142856,0.3551792857142857,0.48479047619047666,0.6225847619047624,0.6895823809523816,0.701325714285715,0.7106661904761911,0.7070500000000006,0.6852976190476197,0.6872928571428578,0.6995895238095244,0.7135566666666674,0.7375928571428578,0.755970952380953,0.7603852380952387,0.7733342857142864,0.791170476190477,0.8040319047619056,0.7845600000000008,0.7761433333333341,0.7658904761904768,0.7713252380952388,0.7770261904761913,0.7881285714285722,0.791208095238096,0.793675714285715,0.7957414285714293,0.8052900000000007,0.8124138095238103,0.8094766666666674,0.8126361904761912,0.806225714285715,0.8086847619047627,0.8044180952380959,0.8062661904761912,0.8045447619047628,0.8127061904761912,0.8132761904761913,0.816578095238096,0.8115076190476198,0.8046709523809531,0.8042757142857151,0.8107542857142864,0.814228095238096,0.8196971428571436,0.8234738095238103,0.8239471428571429,0.8217092857142858,0.8167602380952382],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"fill\":\"tozeroy\",\"fillcolor\":\"rgba(31, 119, 180, 0.3)\",\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003eImprovement:\\u003c\\u002fb\\u003e %{y:.2f}%\",\"line\":{\"color\":\"#1f77b4\",\"shape\":\"spline\",\"width\":2},\"mode\":\"lines\",\"name\":\"mAP50 Improvement\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.0,82.94146527739895,225.33413343516443,377.731711308712,407.1081774043969,418.12776171512735,411.8487807539141,410.5831651301075,420.74627679886527,424.1885330860291,397.4633135126289,379.58103758660195,425.53597730620265,416.5348317058535,422.39921444547485,422.8410888658557,427.67988653101304,432.4095794010147,426.5342861818777,422.4592220828105,427.9417380393868,421.1226883421526,423.6157329114615,428.6181877693525,425.039550488244,428.20358954776066,432.41503464077243,434.0897932464132,425.98876220609895,428.5199934537123,428.19267906824507,434.88080301129236,432.62778899132616,432.95510337679343,429.85652719437024,432.9223719382467,426.36517374938626,430.8930227483498,429.7637881184878,426.03785936391904,428.8964049969996,432.16954885167206,426.03785936391904,424.97408761115054,431.7876820686269,425.6178059025694,426.0815012819814,425.41050679177357,425.0450057280017,424.6958703835033],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"fill\":\"tozeroy\",\"fillcolor\":\"rgba(255, 127, 14, 0.3)\",\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003eImprovement:\\u003c\\u002fb\\u003e %{y:.2f}%\",\"line\":{\"color\":\"#ff7f0e\",\"shape\":\"spline\",\"width\":2},\"mode\":\"lines\",\"name\":\"mAP50-95 Improvement\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.0,89.26842036382672,332.1423897395628,555.7780395236224,733.817563146185,791.4539981677789,852.362256249182,792.1999738254154,792.448632377961,880.4737599790602,765.4757230728961,760.855908912446,865.528072241853,903.3765213977227,875.8146839418923,848.0565371024735,947.9911006412772,940.7800026174582,941.368930768224,929.982986520089,930.0615102735243,877.3720717183613,917.3144876325088,909.0302316450726,955.4770318021202,918.8457008244993,936.6182436853813,951.132050778694,942.6645726999081,969.8599659730402,959.58644156524,971.7445360554899,935.0477686166732,975.2519303756053,943.0441041748461,968.8653317628582,936.317235963879,964.2716921868864,973.9170265672032,970.9331239366575,954.3776992540243,955.7387776469047,955.7126030624263,949.0511713126554,973.9039392749639,978.7724119879595,966.8106268812983,981.3375212668499,973.7207171836146,970.6582907996335],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003emAP50-95\\u002fmAP50:\\u003c\\u002fb\\u003e %{y:.4f}\",\"line\":{\"color\":\"#9b59b6\",\"shape\":\"spline\",\"width\":2.5},\"marker\":{\"color\":\"#9b59b6\",\"line\":{\"color\":\"white\",\"width\":1},\"size\":7,\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"Convergence Ratio\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.4168348698925318,0.4312509318622335,0.5536831161862602,0.5721854909618261,0.6853847974354009,0.7171766093200531,0.7755763266437166,0.7283829264383781,0.7143665276875694,0.7796730114789413,0.7252001315933764,0.7482254982254982,0.7658196312904832,0.8097078765604208,0.7786259541984732,0.7558377329354562,0.8278489387877472,0.8148489692200499,0.8244076295858846,0.8217537484859875,0.8132820814863035,0.7817789734839365,0.8098537256209367,0.7956574235560004,0.8379552184529067,0.8040278853601859,0.8115823232271484,0.8203648471972544,0.8262894242835955,0.8437806426308021,0.836195945178315,0.8352150455384553,0.8100290876316113,0.8409760890926956,0.820556379210938,0.8360323472208006,0.820672000663295,0.8356213650095562,0.8449918134917774,0.8486124362218442,0.8309782160244243,0.8269333278661637,0.8365516240096237,0.8329575093782797,0.8417656593012043,0.8555074674886612,0.8452756232112489,0.8578800369628191,0.8524302308667373,0.8505645546983843],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(155, 89, 182, 0.5)\",\"dash\":\"dash\",\"width\":1.5},\"mode\":\"lines\",\"name\":\"Ideal Convergence\",\"x\":[1.0,50.0],\"y\":[1.0,1.0],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003eChange:\\u003c\\u002fb\\u003e %{y:.4f}\",\"line\":{\"color\":\"#1f77b4\",\"shape\":\"spline\",\"width\":2},\"mode\":\"lines\",\"name\":\"mAP50 Rate of Change\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.10224999999999998,0.12575199999999997,0.14925399999999994,0.15329399999999996,0.12058399999999998,0.06791599999999998,0.015769999999999992,0.006262000000000011,-0.007575999999999981,-0.011830000000000004,0.005482000000000007,-0.0015439999999999898,-0.0006560000000000107,0.009303999999999998,0.01763399999999999,0.00252000000000001,0.003665999999999991,0.000022000000000011106,0.0018699999999999932,-0.002404000000000006,-0.0032240000000000038,0.0007640000000000086,0.0009460000000000023,0.00009600000000000727,0.004140000000000009,0.0038399999999999984,-0.0009640000000000089,0.001275999999999988,-4.000000000004217e-6,0.0009039999999999934,-0.000536000000000003,0.0025540000000000116,0.0004900000000000121,0.0017339999999999908,-0.0031220000000000024,-0.0006359999999999916,-0.0011700000000000048,-0.0014000000000000006,-0.0014759999999999882,0.002128000000000018,-0.0017800000000000032,-0.0017560000000000015,0.0021079999999999983,-0.001202000000000014,-0.002232000000000011,-0.00022999999999999713,0.00002599999999999261,-0.0026000000000000016,-0.0006179999999999918,0.0013640000000000145],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"hovertemplate\":\"\\u003cb\\u003eEpoch:\\u003c\\u002fb\\u003e %{x}\\u003cbr\\u003e\\u003cb\\u003eChange:\\u003c\\u002fb\\u003e %{y:.4f}\",\"line\":{\"color\":\"#ff7f0e\",\"shape\":\"spline\",\"width\":2},\"mode\":\"lines\",\"name\":\"mAP50-95 Rate of Change\",\"x\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0],\"y\":[0.03719200000000001,0.07466700000000003,0.11214199999999998,0.12094999999999997,0.11661599999999998,0.07030599999999998,0.036168,0.02241199999999998,-0.003970000000000006,-0.013983999999999991,0.011206,0.016952000000000005,-0.0007119999999999982,0.012620000000000006,0.028597999999999985,0.011499999999999996,0.005806000000000001,0.008278000000000006,0.012532000000000007,-0.010792000000000001,-0.0035859999999999998,-0.004942000000000002,0.0038960000000000106,-0.0017140000000000141,0.009054000000000006,0.005168000000000016,0.005139999999999988,0.0021979999999999886,0.006225999999999996,0.005367999999999994,-0.0024580000000000036,0.004980000000000004,-0.004098000000000001,0.0014180000000000078,-0.0054139999999999865,0.0044659999999999925,-0.00020400000000000452,0.004262000000000011,-0.002214000000000004,0.0029679999999999928,-0.001307999999999998,-0.003800000000000003,0.0004539999999999988,0.003727999999999997,0.0016920000000000047,0.003916000000000008,0.0037700000000000056,-0.0004960000000000069,-0.0013760000000000118,-0.002256000000000015],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(0, 0, 0, 0.3)\",\"dash\":\"dash\",\"width\":1.5},\"mode\":\"lines\",\"showlegend\":false,\"x\":[1.0,50.0],\"y\":[0,0],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.46],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Epochs\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.56,1.0],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Performance (mAP)\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false,\"range\":[0.65,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.54,1.0],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Epochs\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.56,1.0],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Improvement from Baseline (%)\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.46],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Epochs\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.44],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Convergence Ratio (mAP50-95\\u002fmAP50)\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.54,1.0],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Epochs\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.44],\"title\":{\"font\":{\"size\":13,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"text\":\"Rate of Change\"},\"tickfont\":{\"size\":11,\"family\":\"Arial, sans-serif\",\"color\":\"#2C3E50\"},\"gridcolor\":\"#E4E4E4\",\"showline\":true,\"linewidth\":2,\"linecolor\":\"#E4E4E4\",\"zeroline\":false},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Primary Metrics Performance\",\"x\":0.23,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Performance Improvement from Baseline\",\"x\":0.77,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Convergence Analysis\",\"x\":0.23,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.44,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Learning Stability\",\"x\":0.77,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.44,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"arrowcolor\":\"#1f77b4\",\"arrowhead\":2,\"arrowsize\":1,\"arrowwidth\":2,\"bgcolor\":\"#1f77b4\",\"bordercolor\":\"#1f77b4\",\"borderpad\":4,\"borderwidth\":1,\"font\":{\"color\":\"white\",\"size\":11},\"showarrow\":true,\"text\":\"Best mAP50: 0.9805\",\"x\":32.0,\"xref\":\"x\",\"y\":0.98049,\"yref\":\"y\"},{\"arrowcolor\":\"#ff7f0e\",\"arrowhead\":2,\"arrowsize\":1,\"arrowwidth\":2,\"bgcolor\":\"#ff7f0e\",\"bordercolor\":\"#ff7f0e\",\"borderpad\":4,\"borderwidth\":1,\"font\":{\"color\":\"white\",\"size\":11},\"showarrow\":true,\"text\":\"Best mAP50-95: 0.8263\",\"x\":48.0,\"xref\":\"x\",\"y\":0.82625,\"yref\":\"y\"},{\"arrowcolor\":\"#ff7f0e\",\"arrowhead\":2,\"arrowsize\":1,\"arrowwidth\":2,\"bgcolor\":\"#ff7f0e\",\"bordercolor\":\"#ff7f0e\",\"borderpad\":4,\"borderwidth\":1,\"font\":{\"color\":\"white\",\"size\":11},\"showarrow\":true,\"text\":\"Highest Improvement: 981.3%\",\"x\":48.0,\"xref\":\"x2\",\"y\":981.3375212668499,\"yref\":\"y2\"},{\"arrowcolor\":\"#e74c3c\",\"arrowhead\":2,\"arrowsize\":1,\"arrowwidth\":2,\"bgcolor\":\"#e74c3c\",\"bordercolor\":\"#e74c3c\",\"borderpad\":4,\"borderwidth\":1,\"font\":{\"color\":\"white\",\"size\":11},\"showarrow\":true,\"text\":\"Training Plateau Detected\",\"x\":25.0,\"xref\":\"x4\",\"y\":0.004140000000000009,\"yref\":\"y4\"},{\"align\":\"center\",\"bgcolor\":\"rgba(255, 255, 255, 0.9)\",\"bordercolor\":\"#2C3E50\",\"borderpad\":6,\"borderwidth\":1,\"font\":{\"size\":14},\"showarrow\":false,\"text\":\"\\u003cb\\u003eModel Performance Summary\\u003c\\u002fb\\u003e\\u003cbr\\u003eFinal mAP50: 0.9618\\u003cbr\\u003eFinal mAP50-95: 0.8181\\u003cbr\\u003eImprovement: 424.7% & 970.7%\\u003cbr\\u003eConvergence: 85.1%\",\"x\":0.5,\"xref\":\"paper\",\"y\":1.18,\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"#2C3E50\",\"family\":\"Arial, sans-serif\"},\"text\":\"Model's Performance Analytics During Training(Nano)\",\"x\":0.5,\"y\":0.98},\"legend\":{\"font\":{\"family\":\"Arial, sans-serif\",\"size\":12,\"color\":\"#2C3E50\"},\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":-0.15,\"xanchor\":\"center\",\"x\":0.5,\"bgcolor\":\"rgba(255, 255, 255, 0.8)\",\"bordercolor\":\"#E4E4E4\",\"borderwidth\":1},\"margin\":{\"l\":80,\"r\":80,\"t\":180,\"b\":100},\"hoverlabel\":{\"font\":{\"size\":12,\"family\":\"Arial, sans-serif\"},\"bgcolor\":\"white\"},\"paper_bgcolor\":\"#F8F9FA\",\"plot_bgcolor\":\"#F8F9FA\",\"height\":900,\"width\":1200,\"hovermode\":\"x unified\"},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('97d9b1fb-73a9-4862-82ad-be460515a019');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"\nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-db058ea69fcd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Car Theft Model/Logs/Performance_Analytics.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Car Theft Model/Progress Visualizations/Training Progress Detailed_HD.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3833\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m     \u001b[0;31m# Static helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# -------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# Do this first so we don't create a file if image conversion fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     img_data = to_image(\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Raise informative error message if Kaleido is not installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \"\"\"\n\u001b[1;32m    134\u001b[0m \u001b[0mImage\u001b[0m \u001b[0mexport\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m\"kaleido\"\u001b[0m \u001b[0mengine\u001b[0m \u001b[0mrequires\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkaleido\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: \nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n"]}]},{"cell_type":"markdown","source":["# **Testing**"],"metadata":{"id":"zDWHYegiBdid"}},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","import torch\n","import numpy as np\n","from ultralytics import YOLO\n","import cv2\n","import time\n","\n","\n","model = YOLO(\"/content/drive/MyDrive/Car Theft Model/Models/yolov8n_50e_final.pt\")\n","\n","\n","video_path = \"/content/drive/MyDrive/Car Theft Model/Test Inputs\"\n","cap = cv2.VideoCapture(video_path)\n","\n","\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","\n","output_path = \"/content/drive/MyDrive/Car Theft Model/Test Inputs/demo_output_video.mp4\"\n","fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n","###\n","CONFIDENCE_THRESHOLD = 0.88\n","\n","def create_gradient_box(img, x1, y1, x2, y2, color, thickness=2, alpha=0.3):\n","    overlay = img.copy()\n","    cv2.rectangle(overlay, (int(x1), int(y1)), (int(x2), int(y2)), color, -1)\n","    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n","    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n","    return img\n","\n","\n","start_time = time.time()\n","\n","\n","COLORS = {\n","    'high_conf': (0, 0, 255),    # Red for high confidence\n","    'med_conf': (0, 165, 255),   # Orange for medium confidence\n","    'low_conf': (0, 255, 255),   # Yellow for low confidence\n","    'box_highlight': (255, 255, 255)  # White for box highlight\n","}\n","\n","\n","frame_count = 0\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    frame_count += 1\n","\n","    frame_resized = cv2.resize(frame, (640, 640)) if (frame.shape[:2] != (640, 640)) else frame\n","\n","    results = model(frame_resized)\n","\n","    detections = results[0].boxes.data\n","\n","    elapsed_time = time.time() - start_time\n","    mins, secs = divmod(elapsed_time, 60)\n","    timestamp = f\"{int(mins):02d}:{int(secs):02d}\"\n","\n","    header_height = 40\n","    header = np.zeros((header_height, frame_resized.shape[1], 3), dtype=np.uint8)\n","\n","    for i in range(header_height):\n","        alpha = 1.0 - (i / header_height)\n","        header[i, :] = (50, 50, 50 + int(alpha * 50))\n","\n","    cv2.putText(header, f\"Time: {timestamp}\", (10, 25),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n","    cv2.putText(header, f\"Frame: {frame_count}\", (frame_resized.shape[1] - 150, 25),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n","\n","    frame_with_header = np.vstack([header, frame_resized])\n","    frame_with_header = cv2.resize(frame_with_header, (frame_resized.shape[1], frame_resized.shape[0]))\n","    frame_resized = frame_with_header\n","\n","    for det in detections:\n","        x1, y1, x2, y2, conf, cls = det.tolist()\n","        class_id = int(cls)\n","\n","        if conf < CONFIDENCE_THRESHOLD:\n","            continue\n","\n","        if conf > 0.8:\n","            color = COLORS['high_conf']\n","            risk_level = \"HIGH RISK\"\n","        elif conf > 0.65:\n","            color = COLORS['med_conf']\n","            risk_level = \"MEDIUM RISK\"\n","        else:\n","            color = COLORS['low_conf']\n","            risk_level = \"LOW RISK\"\n","\n","        label = f\"{model.names[class_id]}: {conf:.2f}\"\n","\n","        frame_resized = create_gradient_box(frame_resized, x1, y1, x2, y2, color, thickness=2)\n","\n","        corner_length = min(30, int((x2-x1) * 0.3))\n","\n","        cv2.line(frame_resized, (int(x1), int(y1)), (int(x1 + corner_length), int(y1)), COLORS['box_highlight'], 3)\n","        cv2.line(frame_resized, (int(x1), int(y1)), (int(x1), int(y1 + corner_length)), COLORS['box_highlight'], 3)\n","\n","        cv2.line(frame_resized, (int(x2), int(y1)), (int(x2 - corner_length), int(y1)), COLORS['box_highlight'], 3)\n","        cv2.line(frame_resized, (int(x2), int(y1)), (int(x2), int(y1 + corner_length)), COLORS['box_highlight'], 3)\n","\n","        cv2.line(frame_resized, (int(x1), int(y2)), (int(x1 + corner_length), int(y2)), COLORS['box_highlight'], 3)\n","        cv2.line(frame_resized, (int(x1), int(y2)), (int(x1), int(y2 - corner_length)), COLORS['box_highlight'], 3)\n","\n","        cv2.line(frame_resized, (int(x2), int(y2)), (int(x2 - corner_length), int(y2)), COLORS['box_highlight'], 3)\n","        cv2.line(frame_resized, (int(x2), int(y2)), (int(x2), int(y2 - corner_length)), COLORS['box_highlight'], 3)\n","\n","        cv2.line(frame_resized, (int(x1), int(y1)), (int(x1 + corner_length), int(y1)), color, 2)\n","        cv2.line(frame_resized, (int(x1), int(y1)), (int(x1), int(y1 + corner_length)), color, 2)\n","        cv2.line(frame_resized, (int(x2), int(y1)), (int(x2 - corner_length), int(y1)), color, 2)\n","        cv2.line(frame_resized, (int(x2), int(y1)), (int(x2), int(y1 + corner_length)), color, 2)\n","        cv2.line(frame_resized, (int(x1), int(y2)), (int(x1 + corner_length), int(y2)), color, 2)\n","        cv2.line(frame_resized, (int(x1), int(y2)), (int(x1), int(y2 - corner_length)), color, 2)\n","        cv2.line(frame_resized, (int(x2), int(y2)), (int(x2 - corner_length), int(y2)), color, 2)\n","        cv2.line(frame_resized, (int(x2), int(y2)), (int(x2), int(y2 - corner_length)), color, 2)\n","\n","        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n","        text_width = text_size[0] + 10\n","\n","        label_y1 = max(0, int(y1) - 42)\n","        label_y2 = max(0, int(y1) - 10)\n","\n","        overlay = frame_resized.copy()\n","        cv2.rectangle(overlay, (int(x1), label_y1), (int(x1) + text_width, label_y2), color, -1)\n","        cv2.addWeighted(overlay, 0.8, frame_resized, 0.2, 0, frame_resized)\n","\n","        conf_label = f\"Confidence: {conf:.2f}\"\n","        conf_text_size = cv2.getTextSize(conf_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n","        conf_width = conf_text_size[0] + 10\n","\n","        risk_text_size = cv2.getTextSize(risk_level, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n","        risk_width = risk_text_size[0] + 10\n","\n","        risk_y1 = int(y2) + 10\n","        risk_y2 = int(y2) + 30\n","\n","        overlay = frame_resized.copy()\n","        cv2.rectangle(overlay, (int(x1), risk_y1), (int(x1) + risk_width, risk_y2), color, -1)\n","        cv2.addWeighted(overlay, 0.8, frame_resized, 0.2, 0, frame_resized)\n","\n","        cv2.putText(frame_resized, label, (int(x1) + 5, label_y2 - 5),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n","        cv2.putText(frame_resized, risk_level, (int(x1) + 5, risk_y2 - 5),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n","\n","        bar_width = int((x2 - x1) * 0.8)\n","        bar_height = 5\n","        bar_x = int(x1)\n","        bar_y = int(y2) + 35\n","\n","        cv2.rectangle(frame_resized, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (100, 100, 100), -1)\n","\n","        filled_width = int(bar_width * conf)\n","        cv2.rectangle(frame_resized, (bar_x, bar_y), (bar_x + filled_width, bar_y + bar_height), color, -1)\n","\n","    annotated_frame = cv2.resize(frame_resized, (frame_width, frame_height))\n","\n","    out.write(annotated_frame)\n","\n","    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","        break\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n","print(f\"Processed video saved as {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hyt_TOaAVqfw","executionInfo":{"status":"ok","timestamp":1743036038014,"user_tz":-360,"elapsed":19856,"user":{"displayName":"Enamul Hasan Shagato","userId":"01999449340042650940"}},"outputId":"880af16d-9957-4bc1-9a47-65a562b9fd0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.5ms\n","Speed: 2.4ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.6ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 3.1ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.2ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.8ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.8ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 3.0ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 3.0ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.2ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.4ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 3.4ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.6ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 1.9ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.2ms\n","Speed: 2.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.0ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.7ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.5ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.6ms\n","Speed: 2.5ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 3.0ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.1ms\n","Speed: 2.7ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 2.2ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.8ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.4ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 2.2ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 3.1ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.1ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.3ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.6ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.1ms\n","Speed: 2.2ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 1.8ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 1.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 2.6ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.7ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.5ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.1ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 2.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 3.3ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 3.1ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 3.1ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 2.8ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.4ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.3ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.7ms\n","Speed: 2.2ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.0ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.1ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.0ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.8ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.3ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.6ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 2.8ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 3.0ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 3.5ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.1ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.3ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.5ms\n","Speed: 2.4ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.8ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.0ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.7ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 3.7ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.3ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 2.2ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 3.1ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.3ms\n","Speed: 2.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.1ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 3.4ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 3.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.9ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.6ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.7ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.8ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.9ms\n","Speed: 2.2ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 3.2ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.6ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.4ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.3ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 3.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.8ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 3.1ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.9ms\n","Speed: 2.8ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.6ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 3.4ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.4ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 4.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.4ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.2ms\n","Speed: 2.8ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 4.0ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 3.1ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 3.1ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.6ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 3.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.2ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.6ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.5ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.5ms\n","Speed: 2.8ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.2ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.6ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.9ms\n","Speed: 2.6ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.8ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.7ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.9ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.3ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.2ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 3.1ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.3ms\n","Speed: 2.2ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 2.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.4ms\n","Speed: 3.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.9ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 2.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.1ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 3.4ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.2ms\n","Speed: 3.2ms preprocess, 13.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.4ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.2ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.0ms\n","Speed: 2.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.4ms\n","Speed: 2.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.7ms\n","Speed: 2.4ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.2ms\n","Speed: 2.4ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.3ms\n","Speed: 2.6ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.2ms\n","Speed: 2.2ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.1ms\n","Speed: 2.6ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.2ms\n","Speed: 2.6ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.7ms\n","Speed: 3.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.6ms\n","Speed: 2.3ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.9ms\n","Speed: 2.4ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 16.5ms\n","Speed: 2.2ms preprocess, 16.5ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.0ms\n","Speed: 4.3ms preprocess, 16.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.1ms\n","Speed: 2.7ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.4ms\n","Speed: 2.5ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.4ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.9ms\n","Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 2.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 2.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.4ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.3ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.4ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.2ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 2.5ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.6ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.4ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.4ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.5ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.4ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.4ms preprocess, 9.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.4ms\n","Speed: 4.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.8ms\n","Speed: 2.3ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.5ms\n","Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.5ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.2ms\n","Speed: 2.4ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.3ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 4.8ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.3ms\n","Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.0ms\n","Speed: 2.2ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.4ms\n","Speed: 3.4ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.0ms\n","Speed: 4.0ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.8ms\n","Speed: 2.4ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.1ms\n","Speed: 2.4ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.5ms\n","Speed: 2.4ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.6ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.0ms\n","Speed: 3.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.3ms\n","Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 2.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.4ms\n","Speed: 2.4ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.8ms\n","Speed: 3.0ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.4ms\n","Speed: 2.4ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 3.1ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 2.7ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.6ms\n","Speed: 3.0ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.6ms\n","Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.7ms\n","Speed: 2.3ms preprocess, 11.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.6ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.5ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.3ms\n","Speed: 2.4ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.7ms\n","Speed: 2.4ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.7ms\n","Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.2ms\n","Speed: 2.4ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.5ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.2ms\n","Speed: 2.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.8ms\n","Speed: 2.7ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 3.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.9ms\n","Speed: 5.4ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.0ms\n","Speed: 4.1ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 4.2ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 7.7ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 4.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.8ms\n","Speed: 4.8ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.5ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 3.5ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.5ms\n","Speed: 2.4ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.4ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 9.9ms\n","Speed: 2.5ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.2ms\n","Speed: 3.6ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.7ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 2.2ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.6ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.4ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.5ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.5ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 7.9ms\n","Speed: 2.5ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 8.6ms\n","Speed: 2.3ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.2ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.5ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.4ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 3.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.3ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.3ms\n","Speed: 2.3ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.0ms\n","Speed: 2.5ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.3ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.1ms\n","Speed: 2.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.9ms\n","Speed: 2.4ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.4ms\n","Speed: 2.1ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.4ms\n","Speed: 2.6ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.3ms\n","Speed: 2.5ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.4ms\n","Speed: 3.0ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.6ms\n","Speed: 2.6ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 18.0ms\n","Speed: 2.6ms preprocess, 18.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.9ms\n","Speed: 4.2ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.0ms\n","Speed: 2.8ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.9ms\n","Speed: 2.5ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.4ms\n","Speed: 5.2ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.4ms\n","Speed: 2.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.2ms\n","Speed: 2.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.2ms\n","Speed: 2.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.6ms\n","Speed: 2.5ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.4ms\n","Speed: 2.7ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.9ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.3ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.5ms\n","Speed: 2.6ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.3ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.4ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 2.3ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.1ms\n","Speed: 2.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.7ms\n","Speed: 6.3ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.5ms\n","Speed: 5.9ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.6ms\n","Speed: 2.3ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.5ms\n","Speed: 2.3ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.0ms\n","Speed: 5.0ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.0ms\n","Speed: 2.5ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.9ms\n","Speed: 2.5ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.1ms\n","Speed: 3.1ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.5ms\n","Speed: 2.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.6ms\n","Speed: 3.7ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 19.4ms\n","Speed: 6.3ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.1ms\n","Speed: 2.9ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.9ms\n","Speed: 2.6ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 17.7ms\n","Speed: 2.9ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.1ms\n","Speed: 2.5ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.7ms\n","Speed: 2.4ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.4ms\n","Speed: 2.3ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 17.8ms\n","Speed: 2.5ms preprocess, 17.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.6ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.3ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.2ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.3ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.2ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.4ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.3ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.6ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.6ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.4ms\n","Speed: 2.6ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 3.2ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.3ms\n","Speed: 2.6ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.6ms\n","Speed: 2.7ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.4ms\n","Speed: 2.8ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.4ms\n","Speed: 2.8ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.1ms\n","Speed: 2.5ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.0ms\n","Speed: 2.6ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.9ms\n","Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.4ms\n","Speed: 2.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.9ms\n","Speed: 2.3ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 4.0ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.3ms\n","Speed: 2.7ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.9ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.6ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 3.0ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.4ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.7ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.9ms\n","Speed: 2.3ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.6ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.5ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 3.0ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.4ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.5ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.5ms\n","Speed: 3.5ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.2ms\n","Speed: 2.7ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 3.8ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.8ms\n","Speed: 3.9ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 2.5ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.6ms\n","Speed: 2.3ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 2.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 2.4ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.0ms\n","Speed: 2.4ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.0ms\n","Speed: 2.9ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.9ms\n","Speed: 2.2ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.8ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.9ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.8ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.5ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.4ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.4ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.4ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.5ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.9ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.6ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.2ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.7ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.3ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.6ms\n","Speed: 2.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.3ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.7ms\n","Speed: 3.8ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.6ms\n","Speed: 3.1ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 20.1ms\n","Speed: 2.4ms preprocess, 20.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.4ms\n","Speed: 2.3ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.4ms\n","Speed: 2.3ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 2.2ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 9.2ms\n","Speed: 3.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 11.8ms\n","Speed: 5.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 7.7ms\n","Speed: 2.4ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.7ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 stealing, 7.9ms\n","Speed: 2.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 3.3ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.7ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.8ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.4ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.8ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.8ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.1ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.4ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.6ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 3.7ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.4ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.5ms\n","Speed: 2.4ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.8ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.8ms\n","Speed: 3.5ms preprocess, 15.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.9ms\n","Speed: 4.5ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.0ms\n","Speed: 3.6ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 14.3ms\n","Speed: 3.3ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.0ms\n","Speed: 2.5ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.4ms\n","Speed: 2.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.2ms\n","Speed: 2.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.8ms\n","Speed: 3.9ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.2ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.1ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.4ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.3ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.5ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.4ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 3.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.2ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 2.1ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.3ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.2ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.1ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.6ms\n","Speed: 2.9ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.4ms\n","Speed: 2.5ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 2.7ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 3.7ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.3ms\n","Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.7ms\n","Speed: 2.4ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.9ms\n","Speed: 2.2ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.3ms\n","Speed: 2.5ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 12.3ms\n","Speed: 2.7ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 4.1ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.9ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.3ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.3ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.5ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.5ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.2ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.3ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.7ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.3ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.2ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.2ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.2ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.3ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.3ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.3ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.3ms\n","Speed: 2.3ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.6ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.5ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.4ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.4ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.8ms\n","Speed: 2.5ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.7ms\n","Speed: 2.5ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.4ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.8ms\n","Speed: 2.5ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.3ms\n","Speed: 2.8ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.2ms\n","Speed: 3.2ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.9ms\n","Speed: 2.5ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.9ms\n","Speed: 2.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.4ms\n","Speed: 2.4ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 15.0ms\n","Speed: 2.1ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.9ms\n","Speed: 2.5ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 11.2ms\n","Speed: 2.2ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 13.3ms\n","Speed: 2.5ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 16.2ms\n","Speed: 3.2ms preprocess, 16.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.3ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.9ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.5ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.0ms\n","Speed: 2.4ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.5ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.4ms\n","Speed: 2.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.3ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.8ms\n","Speed: 3.0ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.1ms\n","Speed: 2.8ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.5ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.2ms\n","Speed: 2.9ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.5ms\n","Speed: 2.3ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.9ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.7ms\n","Speed: 2.6ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.3ms\n","Speed: 2.7ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.6ms\n","Speed: 2.6ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.5ms\n","Speed: 2.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.9ms\n","Speed: 2.7ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.6ms\n","Speed: 2.4ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 7.4ms\n","Speed: 2.4ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 8.9ms\n","Speed: 2.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 9.2ms\n","Speed: 2.2ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.2ms\n","Speed: 2.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.1ms\n","Speed: 2.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 (no detections), 10.8ms\n","Speed: 2.3ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","Processed video saved as output_video.mp4\n"]}]}]}